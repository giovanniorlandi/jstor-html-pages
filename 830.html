
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>830</title>
    </head>
    <body>
        <h1>830</h1>
        <p><strong>URL:</strong> <a href="http://doi.org/10.1155/2019/1345202">http://doi.org/10.1155/2019/1345202</a></p>
        <p><strong>Full Text:</strong></p>
        <pre>['Research Article\nDesign and Real-Time Implementation of a 3-Stage CnW Heading\nSystem on an Ubuntu Linux-Embedded Board\nFelipe P. Vista IV and Kil To Chong\nElectronic Engineering Department, Chonbuk National University, Jeonju City 54896, Republic of Korea\nCorrespondence should be addressed to Kil To Chong; kitchong@jbnu.ac.kr\nReceived 27 December 2018; Accepted 6 February 2019; Published 24 March 2019\nAcademic Editor: Fanli Meng\nCopyright © 2019 Felipe P. Vista IV and Kil To Chong. This is an open access article distributed under the Creative Commons\nAttribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work\nis properly cited.\nThis paper describes the design and real-time implementation of a proposed algorithm for deriving an accurate heading\nsystem by fusing data from various inexpensive sensor devices that is comparable to more expensive maritime navigation\nsystems. The proposed algorithm is a 3-Stage Classification N’ Weighing (CnW) Heading System with forward azimuth\n(FAz) and extended Kalman filter (EKF). Data from three Global Positioning System devices, an inertial measurement unit,\nand an electronic compass were fed into the algorithm that can be generally described as Classification N’ Weighing-Stage\n1→ forward azimuth→Classification N’ Weighing-Stage 2→ extended Kalman filter→Classification N’ Weighing-Stage 3.\nThe proposed algorithm is shown to be comparably accurate as an expensive marine navigation system, and it has less\nprocessing time compared to our previous work. The Qt-anywhere-based system developed on a Linux desktop was\nsuccessfully downloaded onto an Ubuntu Linux-embedded board for real-time implementation. Important notes related to\ndevice naming problems when deploying the system on a Linux-embedded board are also given as reference for those\ninterested to address it.\n1. Introduction\nSensor data fusion is integral in deriving better and more\naccurate data from varied sources such as Global Navigation\nSatellite System- (GNSS-) Global Positioning System (GPS)\n[1], cellular handoff [2], electronic nose/electronic tongue\n[3], webcam [4], radar, smartphone [5], StarGazer [6], and\na host of other sensors (compass, inertial measurement, pressure,\naccelerometer, gyroscope, wheel speed, lateral accelera-\ntion, steering wheel angle, tilt, microwave, ultrasonic, vision,\naltimeter, etc.).\nIt is applied in various settings such as navigation/\nlocalization/positioning for both indoor [7, 8] or outdoor\n[9–11] as well as in pedestrian dead-reckoning [12, 13],\nmobile robots [14, 15], and even for research works related\nto extraterrestrial navigational purposes [16, 17]. Sensor\nfusion was used in the design of an assistive instrument for\nparaglider and hang-glider pilots [18]. There are also\nresearch works that were focused mainly on deriving a more\naccurate heading information [1, 19].\nIn the field of safety and security, there are systems that\nwere designed to detect and track road barriers such as tunnels\nor guardrails [20], estimating the speed of vehicles on\nthe freeway [2], as well as detection, monitoring, and intelligent\nalarm related to public security [21].\nIn the aspect of maritime industry, several systems were\ndesigned to assist the ship navigator such as leaving or entering\na harbor [22]. There is also the Advanced Sensor Module\npart of the MUNIN project that dealt with unmanned and\nautonomous shipping [23] while another group of works\ndealt with marine collision avoidance [24, 25]. Other maritime\nnavigation-related works focused on obtaining a more\naccurate heading value such as that of Hu and Huang [26]\nand Juang and Lin [27] while others concentrated on improving\nthe attitude and position apart from the heading such as\nthose of Feng-de et al. [28], Bryne [29], Jaroś et al. [30], and\nNúñez et al. [31].\nSensor fusion is utilized in food industry such as in\nimproving the dependability of quality assessment and verification\nof food and beverages [32]. It has also been utilized for\nHindawi\nJournal of Sensors\nVolume 2019, Article ID 1345202, 13 pages\nhttps://doi.org/10.1155/2019/1345202\n', 'identifying the blending ratio between old frying oil and the\nnew edible oil to control production cost [3]. It has even been\nsuccessfully applied in real-time recognition of human action\n[33] as well as recognizing the activity of daily living (ADL)\nin helping indicate one’s capability for quality living and\nhealth status [5].\nVarious fusion methods have been used in previous\nworks just like ad hoc [34], dead reckoning [35], fuzzy\nlogic [36], Kalman filter [6] and its variations [10], neural\nnetworks [2], or numerical discretization [37]. Most of\nthese sensor fusion systems are usually developed for\nembedded systems just like the ones that used FieldProgrammable\nGate Arrays (FPGA) with digital signal\nprocessors (DSP) [38].\nThe current work given in this paper describes the design,\ndevelopment, and successful deployment onto an embedded\nboard of a system for deriving an accurate heading value\nthrough a 3-Stage Classification and Weighing (3-Stage\nCnW) algorithm with forward azimuth (FAz) and extended\nKalman filter (EKF) by fusing data frommultiple inexpensive\ndevices (multiple GPS, an electronic compass, and an IMU).\nThis algorithm is based on our previously proposed work\nthat was checked through postprocessing [39]. The system\nwas developed using Qt-anywhere on a desktop with an\nUbuntu Linux system and then deployed onto an Ubuntu\nLinux-based embedded board using another previous work\nof ours [40]. The proposed algorithm was tested and\nvalidated to generate a more accurate heading value compared\nto the individual GPS COG values and is even com-\nparable to the more expensive Furuno Satellite Compass\n(GPS Compass) Model SC-50. This paper is arranged with\nthe proposed 3-Stage Classification and Weighing proposed\nalgorithm in Section 2. The experimental tests\ncomposed of the postprocessing and real-time implementation\nsubsections are given in Section 3 followed by the\nconcluding remarks.\n2. Proposed 3-Stage Classification and\nWeighing Sensor Fusion Algorithm\nThe system design for the proposed sensor fusion system is\ngiven in Figure 1. The proposed algorithm is composed of\nseveral steps that includes three stages of Classification and\nWeighing which was inspired by the work of Ercan et al.\n[34], initial heading calculation for each GPS using forward\nazimuth [41], and then multiple extended Kalman filters.\nThe simplified algorithm for the whole process is given\nin Figure 2.\n2.1. Classification and Weighing-Stage 1 (CnW-S1). The first\nstage classifies and assigns weight to the calculated FAz heading\nfor each GPS device. This is done by evaluating the FIX\nand HDOP (Horizontal Dilution of Precision) values. The\nGGA NMEA sentence provides crucial fix data in terms of\nthe 3D accuracy and location while the FIX value from the\nGGA NMEA sentence indicates the quality of the system\nfix. The FIX value classification based on the description\ngiven by DePriest [42] assigns values for corresponding measurements\n(Code 1).\nThe GSA NMEA sentence provides information on\nthe inherent characteristics of the FIX wherein the HDOP\nvariable of the GSA sentence is available to telemetry\nusers in overseeing control on the quality of the location.\nDussault et al. [43] showed that the probability of attaining\nan inaccurate location value increases when the satellite\ngeometry is poor. The classification for the HDOP values\nbased on Yuen’s [44] work is noted in Code 2.\nThe results of the previous classifications for FIX and the\nclassified HDOP values are then further evaluated using our\nown classification method. The respective weight values\nassigned relative to the resulting descriptive classifications\nwill then be utilized as inputs for both Classification and\nWeighing Stage-2 and Classification and Weighing Stage-3.\nHence, the values generated are very integral in deriving the\noverall heading value for the system. The first classification\nand weighing stage is given in Code 3.\n2.2. Forward Azimuth. The initial calculated heading for each\nGPS is derived using the forward azimuth (FAz) method by\ntaking the current (latcurr, longcurr) and previous (latprev,\nlongprev) values. The formula for deriving the heading ψFAz\nthrough FAz (1) is given as follows:\nx1 = sinΔlong∗ cos latcurr,\nx2 = cos latprev∗ sin latcurr − sin latprev cos latcurrΔlong,\nψFAz = tan−1 x1, x2 + 180\n1\n2.3. Classification and Weighing-Stage 2 (CnW-S2). The second\nstage fuses heading data from the GPS devices and the\nEC using the equation given in (2). The computed FAz GPS\nGPS1 GPS2 GPS3 EC\nFused heading\nvalue\nHeading\nIMU\nAcceleration,\nGyroscope\nLat,\nLon,\nFix,\nHDOP \nLat,\nLon,\nFix,\nHDOP \nLat,\nLon,\nFix,\nHDOP \nxXx\nLinux system\n(desktop/ embedded)\nFigure 1: System design.\nCnW-S1\nGPSi, EC\n& IMU FAz\nCnW-S2\nEKF\nCnW-S3\nFigure 2: Complete simplified algorithm.\n2 Journal of Sensors\n', 'heading andmeasured EC heading are fused while taking into\nconsideration the derived weights from CnW-S1.\nhfused = hallGPS wallGPS + hEC wEC ,\nhallGPS =\n∑n1 wihi\n∑n1wi\n,\nwallGPS =\n∑n1wi\nn∗idealValue ,\nwEC = 1 −wallGPS ,\n2\nwhere n is the total number of GPS devices, idealValue is\nthe IDEAL weight value from CnW-S1, hfused is the fused\nEC and GPS heading value, hallGPS is the fused calculated\nheading for all the “n” number of GPS, wallGPS is the weight\ngiven to calculated combined GPS heading, hEC is the\nmeasured EC heading, wEC is the weight given to EC\nheading, wi is the weight given to “i\nth” GPS, hi is the calculated\nFAz heading of “ith” GPS, and ∗hfused is labeled as\n“GPSEC_yaw” in the later parts of algorithm and it will also\nbe used in lieu of GPSn_FAz during the EKF stage when\nGPS data is invalid.\n2.4. Extended Kalman Filter. The state estimate is\nderived in the extended Kalman filter through the following\nsteps:\n(1) State and error covariance prediction\n(2) Kalman gain computation\n(3) Time updating of the estimate\n(4) Time updating of the error covariance\nThe controllability and observability of the extended\nKalman filter or Kalman filter have been extensively researched\nand proven in several works such as those by\nElizabeth and Jothilakshmi [45], Kamrani et al. [46], and\nSouthall et al. [47]. The dynamic and measurement models\nwhich are nonlinear in nature are as follows:\nxk+1 = f xk +wk,\nzk = h xk + vk,\n3\nwhere xk and zk are the state estimate and measurement.\nThe nonlinearity of the system is the reason why EKF\n(i) If Invalid then “FIXGi_class = 0”\n(ii) If GPS mode or Standard Positioning Service then “FIXGi_class = 1”\n(iii) If Differential GPS mode (DGPS) then “FIXGi_class = 2”\n(iv) If Precise Positioning System then “FIXGi_class = 3”\n(v) If Real Time Kinematics then “FIXGi_class = 4”\n(vi) If Float Real Time Kinematics then “FIXGi_class = 5”\n(vii) If Estimated Fix or Dead Reckoning then “FIXGi_class = 6”\n(viii) If Manual Input mode then “FIXGi_class = 7”\n(ix) If Simulation mode then “FIXGi_class = 8”\nCode 1\n(i) If (0 < HDOP <= 1) then “HDOPGi_class = IDEAL”\n(ii) If (1 < HDOP <= 2) then “HDOPGi_class = EXCELLENT”\n(iii) If (2 < HDOP <= 5) then “HDOPGi_class = GOOD”\n(iv) If (5 < HDOP <= 10) then “HDOPGi_class = MODERATE”\n(v) If (10 < HDOP <= 20) then “HDOPGi_class = FAIR”\n(vi) If (20 < HDOP) then “HDOPGi_class = POOR”\nCode 2\n(i) If (2 <= FIXGi_class <= 5) and (0 < HDOP <= 2) then IDEAL, with weight “3”\n(ii) If (FIXGi_class == 1) and (0 < HDOP <= 2) then EXCELLENT, with weight “2”\n(iii) If (2 <= FIXGi_class <= 5) and (2 < HDOP <= 5) then EXCELLENT, with weight “2”\n(iv) If (2 <= FIXGi_class <= 5) and (5 < HDOP <= 10) then GOOD, with weight “1”\n(v) If (FIXGi_class == 1) and (2 < HDOP <= 5) then GOOD, with weight “1”\n(vi) Else BAD, with weight “0”\nCode 3\n3Journal of Sensors\n', 'was utilized for this work. The predicted state x̂−k+1 and\nerror covariance P−k+1 can be derived through\nx̂−k+1 = f x̂+k ,\nP−k+1 = FkPkFTk +Qk,\n4\nwhere Fk is the Jacobian matrix of the nonlinear dynamic\nmodel and Pk is the updated state covariance matrix of\nprevious time step k. Qk is the process noise, and Rk is\nthe measurement noise covariance matrix which are\nassumed to be positively definite. The predicted measurement\nẑ−k+1 is derived as\nẑ−k+1 = h x̂−k+1 5\nThe innovation covariance Pvvk+1 of the residual error\nbetween observed and predicted measurements is\nPvvk+1 = P\nyy\nk+1 + Rk+1 =Hk+1P−k+1HTk+1 + Rk+1, 6\nwhere Pyyk+1 =Hk+1P−k+1HTk+1 is the output covariance\nmatrix and Hk+1 is the Jacobian matrix of the measurement\nfunction h x̂−k+1 that is evaluated about the pre-\ndicted state x̂−k+1. The Kalman gain is calculated as\nKk+1 = P\nxy\nk+1 P\nvv\nk+1\n−1 = P−k+1HTk+1 Pvvk+1 −1 7\nThe state vector xk of the dynamic model which has the\nelements latitude, longitude, and heading, xk = xN , yE, ψ\nT ,\nis defined by\nx =\nxN\nyE\nψ\n=\ncos ψ −sin ψ 0\nsin ψ cos ψ 0\n0 0 1\nu\nv\nr\n+w\n=\nu cos ψ − v sin ψ\nu sin ψ + v cos ψ\nr\n+w = f x +w\n8\nOn the other hand, the measurement model h xk is\ndescribed as\nyk =\nxN ,k\nyE,k\nψk\n=\n1 0 0\n0 1 0\n0 0 1\nxN ,k\nyE,k\nψk\n=Hkxk + vk 9\nThe measurements for estimating the state are taken\nfrom three GPS devices and one EC. The covariance for\nprocess noise (Q) and measurement noise (R) was set dependent\non the measured values as\nQ =\n0 01 0 0\n0 0 01 0\n0 0 10\n,\nRk =\n0 3 0 0\n0 0 07 0\n0 0 0 03\n10\n2.5. Classification andWeighing-Stage 3 (CnW-S3). The third\nstage was developed to address the difficulty in deploying to\nan embedded board the previously proposed algorithm that\nutilized the Covariance Intersection algorithm [39, 40]. This\nstage fused the heading values from the multiple EKF processes\nwith their corresponding weight values from the first\nstage (CnW-S1). The equation for this step is given as follows:\nhCnW‐S3 =\n∑n1wihEKFi\n∑n1wi\n, 11\nwhere n is the total number of EKF’s;wi is the weight for GPSi\nfrom CnW-S1; hEKFi is the heading value from EKF number i;\nhCnW−S3 is the overall fused heading value.\nThe graphical representations of these steps are given in\nFigures 3 and 4.\n3. Experimental Tests\n3.1. Postprocessing Simulation. The proposed algorithm was\ninitially tested through postprocessing via MATLAB using\nthe device setup given in Figure 5 to capture the data. There\nwere two sets of data captured two days apart using three\ninexpensive GPS, an electric compass, an IMU, and Furuno\nSatellite Compass (GPS Compass) Model SC-50 which was\nfor comparative performance. The SC-50 has a heading\naccuracy of 0.5 degrees RMS. The reference heading is\n18.01 degrees based on Google Earth (Figure 6).\nThe results of the experimental tests via postprocessing\nare given in Figure 7 with the left column showing the derived\nheading value while the heading error is given in the right column,\nas compared to EKF-CI, GPS#1 COG, GPS#2 COG,\nGPS#3 COG, and EC. The 1st and 2nd data sets have artificially\nintroduced data blackouts for all the three GPS devices\nhence the very noticeable increase in their respective COG\nRMSEs. The RMSE for electronic compass on the other hand\nis a result of the actual measured value during the second data\ncapture run. Additional plots of postprocessing results without\nmissing GPS data are given in Figure 8.\nThe RMSEs for both data sets with complete GPS data\nand with missing GPS data are given in Tables 1 and 2,\nrespectively. It can be seen that the proposed 3-Stage CnW\nperformed better compared to EKF-CI for both situations.\nThe postprocessing time for both methods with the same\nset of data is given in Table 3. It shows that the proposed\n3-Stage CnW compared with EKF-CI has a factor of\n4 Journal of Sensors\n', 'approximately 1 is to 27 in terms of processing time. This\nreduction in processing time opens the opportunity for\nmore real-time application of the proposed heading system\naside from marine vehicles such as land vehicles or even\naerial vehicles.\nThe decrease in processing time is directly due to the\nlesser complexity of the proposed algorithm compared to\nthe previous algorithm especially the use of the CnW-Stage\n3 (13) instead of the Covariance Intersection (CI) [48] algorithm\nwhich is more complicated in itself and has to be per-\nformed thrice. The first CI implementation processes the\nEKF1_output and EKF2_output, and the second CI works on\nFAz-1\n(GPS1_yaw)\nFAz-2\n(GPS2_yaw)\nCnWS1-1\n(Weight1)\nCnWS1-2\n(Weight2)\nGPS-1\nvalid?\nGPS-2\nvalid?\nGPS-3\nvalid?\nGPS1\n(Fix, HDOP, Lat, Lon)\nGPS2\n(Fix, HDOP, Lat, Lon)\nGPS3\n(Fix, HDOP, Lat, Lon)\nYes No\nWeight1 = 0,\nGPS1_yaw = 0\nWeight2 = 0,\nGPS2_yaw = 0\nFAz-3\n(GPS3_yaw)\nCnWS1-3\n(Weight3)\nWeight3 = 0,\nGPS3_yaw = 0\nYes No Yes No\nCnW-S2\n(GPSEC_yaw)\nEC\n(EC_yaw)\nFigure 3: CnW-S1, FAz, and CnW-S2.\nCnW-S2\n(GPSEC_yaw)\nCnW-S2\n(GPSEC_yaw)\nEKF1\n(EKF1_yaw)\nGPS1\n(Lat, Lon)\nEKF2\n(EKF2_yaw)\nEKF3\n(EKF3_yaw)\nGPS2\n(Lat, Lon)\nGPS3\n(Lat, Lon)\nIMU\n(Acc_x, Acc_y, Gyro_x, Gyro_y)\nCnW-S3\n(CnWIII_yaw)\nCnW-S1-1\n(Weight1)\nCnW-S1-2\n(Weight2)\nCnW-S1-3\n(Weight3)\nFigure 4: EKF and CnW-S3.\nFigure 5: Data gathering setup for postprocessing.\nFigure 6: Reference heading via Google Earth of 18.01 degrees.\n5Journal of Sensors\n', 'the EKF2_output and EKF3_output, while the third CI\nimplementation utilizes the outputs of CI_1 and CI_2 as\nits input. There is no perceived trade-off since the derived\nheading accuracy also improved with the decrease in processing\ntime.\n3.2. Real-Time Implementation. The proposed algorithm\nwas initially developed using Qt-everywhere on a desktop\nrunning Ubuntu Linux. The TinyEKF library of Simon D.\nLevy which can be accessed at GitHub [49] was utilized\nfor the EKF aspect of the algorithm when deployed on\nan embedded board. It was chosen due to it being a\nC/C++ implementation of EKF that can be deployed on\nArduinos, STM32, and other embedded systems. The\ndevices in Figure 9 were utilized during the real-time\nimplementation. The program was then uploaded to the\n0 1000 2000 3000 4000 5000 6000\nSamples\n17\n12\n13\n14\n15\n16\n18\n19\n20\n21\n22\nH\nea\ndi\nng\n v\nal\nue\ns\nHeading for 1st data set (missing GPS data)\n3-Stage CnW\nEKF-CI\nCOG1\nCOG2\nCOG3\nEC\n0 1000 2000 3000 4000 5000 6000\nSamples\n1\n0\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\n2\nH\nea\ndi\nng\n v\nal\nue\ns\nHeading errors for 1st data set (missing GPS data)\n3-Stage CnW\nEKF-CI\nCOG1\nCOG2\nCOG3\nEC\n(a) 1st data set with missing GPS data\n0 1000 2000 3000 4000 5000 800070006000\nSamples\n10\n0\n5\n15\n20\n25\n30\nH\nea\ndi\nng\n v\nal\nue\ns\nHeading for 2nd data set (missing GPS data)\n3-Stage CnW\nEKF-CI\nCOG1\nCOG2\nCOG3\nEC\n0 1000 2000 3000 4000 5000 800070006000\nSamples\n1\n0\n0.2\n0.4\n0.6\n0.8\n1.2\n1.4\n1.6\n1.8\n2\nH\nea\ndi\nng\n v\nal\nue\ns\nHeading errors for 2nd data set (missing GPS data)\n3-Stage CnW\nEKF-CI\nCOG1\nCOG2\nCOG3\nEC\n(b) 2nd data set with missing GPS data\nFigure 7: 1st and 2nd data set postprocessing results.\n6 Journal of Sensors\n', 'Beagle Bone Black (BBB) board which has the LCD cape\nattached for display purposes.\n3.2.1. Persistent Naming. Persistent naming was implemented\nin the Linux system in order to address the problem\nof a device getting a new assigned name when disconnecting\nand connecting. This is very important in deploying the system\nespecially when developing the system using a desktop\nand then deploying it onto an embedded board. We will be\npresenting a more detailed account of its implementation in\nthis section. The connected device naming convention for\nthe UBUNTU Linux system that is being currently utilized\nis “/dev/ttyACM0” for GPS#1, “/dev/ttyACM1” for\nGPS#2, “/dev/ttyACM2” for GPS#3, “/dev/ttyACM3” for EC\n(Arduino), and “/dev/ttyUSB0” for IMU. The device information\ncan be retrieved through the following commands\n0 1000 2000 3000 4000 5000 800070006000\nSamples\n19.5\n17\n17.5\n18\n18.5\n19\n20\n20.5\n21\n21.5\n22\nH\nea\ndi\nng\n v\nal\nue\ns\nHeading for 1st data set (complete GPS data)\n3-Stage CnW\nEKF-CI\nCOG1\nCOG2\nCOG3\nEC\n0 1000 2000 3000 4000 5000 6000\nSamples\n0\n0.5\n1\n1.5\nH\nea\ndi\nng\n v\nal\nue\ns\nHeading errors 1st data set (complete GPS data)\n3-Stage CnW\nEKF-CI\nCOG1\nCOG2\nCOG3\nEC\n(a) 1st data set, no missing GPS data\n0 1000 2000 3000 4000 5000 800070006000\nSamples\n0\n5\n10\n15\n20\n25\n30\nH\nea\ndi\nng\n v\nal\nue\ns\nHeading for 2nd data set (missing GPS data)\n3-Stage CnW\nEKF-CI\nCOG1\nCOG2\nCOG3\nEC\n0 1000 2000 3000 4000 5000 800070006000\nSamples\n0\n0.5\n1\n1.5\nH\nea\ndi\nng\n v\nal\nue\ns\nHeading for 2nd data set (missing GPS data)\n3-Stage CnW\nEKF-CI\nCOG1\nCOG2\nCOG3\nEC\n(b) 2nd data set, no missing GPS data\nFigure 8: 1st and 2nd data set postprocessing results, with no missing GPS data.\n7Journal of Sensors\n', 'Table 1: RMSE with complete GPS data.\n1st data set 2nd data set\nGPS#1/#2/#3 (COG) 0.5483, 0.5037, 0.4966 0.8183, 0.5616, 0.5997\nAverage of GPS#1/#2/#3 (COG) 0.5052 0.6211\nElectronic compass 1.6553 10.5455\nEKF-CI 0.4330 0.5122\n3-Stage CnW 0.4262 0.4946\nTable 2: RMSE with the all three GPS missing some data.\n1st data set 2nd data set\nGPS#1/#2/#3 (COG) 6.2169, 2.3857, 5.2544 5.4118, 4.9847, 4.5608\nAverage of GPS#1/#2/#3 (COG) 2.7220 2.7520\nElectronic compass 1.6553 10.5455\nEKF-CI 0.4633 0.9467\n3-Stage CnW 0.4222 0.5012\nTable 3: Comparative postprocessing time.\nComplete GPS data With missing GPS data\n1st set (6001 data set) 2nd set (8001 data set) 1st set (6001 data set) 2nd set (8001 data set)\nEKF-CI 27.082907 secs 36.388161 secs 28.040673 secs 36.065577 secs\n3-Stage CnW 0.990270 secs 1.268189 secs 1.005248 secs 1.264782 secs\nFACTOR 27 28 27 28\n(a) GPS (b) IMU\n(c) Arduino with EC (d) BBB\n(e) LCD cape\nFigure 9: Devices utilized for real-time development.\n8 Journal of Sensors\n', 'For EC (Arduino) : “udevadm info –a –n /dev/ttyACM0”\nFor IMU : “udevadm info –a –n /dev/ttyUSB0”\nFor GPS#1 : “udevadm info –a –n /dev/ttyACM1”\nFor GPS#2 : “udevadm info –a –n /dev/ttyACM2”\nFor GPS#3 : “udevadm info –a –n /dev/ttyACM3”\nCode 4\n(a) EC (Arduino Uno) (/dev/ttyACM0) (b) IMU (/dev/ttyUSB0)\n(c) GPS #1 (/dev/ttyACM1) (d) GPS #2 (/dev/ttyACM2)\n(e) GPS #3 (/dev/ttyACM3)\nFigure 10: Results for “udevadm info –a –n/dev/ttyXXX#” (Ubuntu Linux on BBB).\nFor IMU : SUBSYSTEM, ATTRS{idVendor}, ATTRS{idProduct},\nATTRS{serial}\nFor EC via Arduino, GPS#1, GPS#2, and GPS#3: SUBSYSTEM, KERNELS, ATTRS{idVendor},\nATTRS{idProduct}, ATTRS{Product}, ATTRS{serial}\nCode 5\n9Journal of Sensors\n', 'executed at a terminal command line in the Ubuntu Linux\nsetup on the BBB embedded board.\nScreen captures of significant portions of the output of\nthe command can be seen in Figure 10. The implemented\nrules file has different configurations for the GPS, EC, and\nIMU. Given below is the pertinent information needed when\nrunning the udevadm command on each of the device that is\nneeded for the persistent naming to work in our system.\nThe four items of information for IMU are enough to\nuniquely identify it while the EC and GPS need the additional\ninformation of ATTRS{Product} and especially KERNELS to\nhelp us identify the device when writing the rules file. It must\nbe noted that the exact information including the number of\nspaces given by the udevadm info –a –n command must be\nused, such as ATTRS{product}==“Arduino Uno” for the\nEC/Arduino while ATTRS{product}==“u-blox 5 - GPS\nReceiver” for the GPS. In terms of having the same devices\non the system such as three GPS devices, this is where the\nKERNELS information is necessary to uniquely identify each\nof them. This is in order to avoid the system from mistakenly\npolling the same GPS device as another GPS when there are\nactually three GPS devices. The KERNELS information for\nEC/Arduino and multiple GPS devices are given as follows:\nThe persistent naming is affected though by the utilization\nof multiple USB hubs in order to accommodate the\nseveral sensor devices that was used in the real-time implementation\nof the sensor fusion system onto an embedded\nboard. The BBB board that was utilized has only one USB\nport hence the need for USB hubs with the first one being a\npowered hub due to the power requirement of the various\nsensor devices that cannot be sufficiently supplied by the\nBBB board itself. The ports where the devices are connected\nmatter when it comes to setting up the persistent names\nthrough a rules file in the Linux system. This information\ncan be fully understood through the help of the diagram\ngiven in Figure 11. Taking for example the KERNELS information\nfor GPS #1, the first set of numbers (“1-1.”) refers\nto the USB port of the BBB itself. The next number (“.1.”)\nrefers to the port number of the powered USB hub that the\nsecond USB hub is connected to. The last number (“.2.”)\nrefers to the port number of the second USB hub that GPS\n#1 is connected. The same logic is given for all the other\ndevices, but it is worth noting that EC via Arduino only has\n(“1-1.4”) since it is directly connected to the fourth port of\nthe powered hub itself.\nWith respect to the rules file, another thing that is necessary\nbut must be supplied by the developer is the symbolic\nlink (SYMLINK) information which will be used in the\nsensor fusion system to refer to the specified device. The\ndeveloper has the freedom to assign any name preferred. A\nscreen capture of the implemented .rules file is given in\nFigure 12 wherein the following symbolic links were utilized:\nThe proper implementation of persistent naming\nwould then enable the fusion system to continue to operate\nproperly even if the device(s) get(s) disconnected and\nthen reconnected again. Given below is the update done\nin the Qt program code for the real-time implementation\nof the system.\n3.2.2. Multithreading. The multithreading feature of the\nembedded board and the installed Ubuntu system were\nexploited since there was a need for the simultaneous polling\nof data from the various sensors as well as the individual\nprocesses of the sensor fusion algorithm. The current\nFor EC (Arduino) : KERNELS==“1-1.4”\nFor IMU : KERNELS==“1-1.1.1”\nFor GPS #1 : KERNELS==“1-1.1.2”\nFor GPS #2 : KERNELS==“1-1.1.3”\nFor GPS #3 : KERNELS==“1-1.1.4”\nCode 6\nBBB\n1 4 3 2 1234\nArduino/EC\nGPS #3\nGPS #2\nGPS #1\nIMU\n5Vdc\nPowered USB hub USB hub\n(1-1)\nFigure 11: USB hub mesh.\nFigure 12: Implemented /etc/udev/rules.d/99-usb-serial.\nrules file (Ubuntu Linux on BBB).\nFor EC (Arduino) : SYMLINK+=“fjEC”\nFor IMU : SYMLINK+=“fjIMU”\nFor GPS #1 : SYMLINK+=“fjGPS1”\nFor GPS #2 : SYMLINK+=“fjGPS2”\nFor GPS #3 : SYMLINK+=“fjGPS3”\nCode 7\nFor EC (Arduino) :\nserialPort->setPortName(“/dev/ttyACM0”)to\nserialPort->setPortName(“/dev/fjEC”)\nFor IMU :\nserialPort->setPortName(“/dev/ttyUSB0”)to\nserialPort->setPortName(“/dev/fjIMU”)\nFor GPS #1 :\nserialPort->setPortName(“/dev/ttyACM1”)to\nserialPort->setPortName(“/dev/fjGPS1”)\nFor GPS #2 :\nserialPort->setPortName(“/dev/ttyACM2”)to\nserialPort->setPortName(“/dev/fjGPS2”)\nFor GPS #3 :\nserialPort->setPortName(“/dev/ttyACM3”)to\nserialPort->setPortName(“/dev/fjGPS3”)\nCode 8\n10 Journal of Sensors\n', 'implementation has a total of eleven (11) threads that are running\nsimultaneously. The multithreading design and their\ninterconnection are graphically represented in Figure 13.\nThe thread and the specific operation they execute are given\nas follows:\nThe resulting real-time implementation of the 3-Stage\nCnW that was programmed on an Ubuntu desktop and then\ndeployed onto a BBB with LCD cape is shown in Figure 14.\nThe test programhas several buttons to individually start/stop\nthe subprocesses related toeachof the threads (Threads#2-11)\nas well as a single button to start/stop the complete sensor\nfusion algorithm. The fusion system was able to operate as\ndesired even when the sensors got disconnected and then\nreconnected as well as when the ports they were connected to\nwere changed. This was successfully addressed by the use\nof persistent naming that would have otherwise broken\nthe system.\n4. Conclusion\nPresented in this paper is the design, development, and\nreal-time deployment of the 3-Stage Classification and\nCnW-S2\nGPS#1\nFAz-1 & CnW-S1-1\nEC\nT1\nT6\nT5\nT4\nT3\nT2\nGPS#2\nFAz-2 & CnW-S1-2\nGPS#3\nFAz-3 & CnW-S1-3\nT7\nIMU\nT8\nEKF1\nT9\nT10\nT11\nEKF2\nEKF3\nCnW-S3Main\nFigure 13: Implementation threads.\nThread 1 - main thread for sensor fusion system;\nThread 2 - poll data, execute CnW-S1 and then FAz on GPS#1;\nThread 3 - poll data, execute CnW-S1 and then FAz on GPS#2;\nThread 4 - poll data, execute CnW-S1 and then FAz on GPS#3;\nThread 5 - poll data from EC;\nThread 6 - execute CnW-S2;\nThread 7 - poll data from IMU;\nThread 8 - execute EKF on data from GPS#1 and IMU;\nThread 9 - execute EKF on data from GPS#2 and IMU;\nThread 10 - execute EKF on data from GPS#3 and IMU;\nThread 11 - execute CnW-S3 on data from EKF#1, EKF#2, and EKF#3\nCode 9\n(a) (b)\nFigure 14: System on BBB.\n11Journal of Sensors\n', 'Weighing algorithm with the forward azimuth (FAz) and\nextended Kalman filter (EKF) that generates an accurate\nheading value. The resulting heading is comparable to more\nexpensive navigation systems such as the Furuno Satellite\nCompass (GPS Compass) Model SC-50 by fusing data from\nmultiple inexpensive sensors. The current algorithm is based\non our previous work [39] that has been further improved.\nThe accuracy of the proposed algorithm is tested and\nvalidated as well as shown to have faster processing time\ncompared to our previously proposed algorithm. The\nalgorithm was initially tested through MATLAB and then\nwas programmed on an Ubuntu-Linux desktop using\nQt-anywhere. The multithreading capability of the desktop\nand target BBB-embedded board was utilized in order to\nsimultaneously implement the fusion processes as well as\npolling data from the individual sensor devices. The complete\nsensor fusion was successfully deployed on an embedded\nboard following the general steps given in our previous work\n[40] with additional focus on persistent naming to address\nthe problemof device name reassignment in the Linux system.\nData Availability\nThe GPS, IMU, and EC data used to support the findings\nof this study are available from the corresponding author\nupon request.\nConflicts of Interest\nThe authors declare that they have no conflicts of interest.\nAcknowledgments\nThis research is supported by the Brain Research Program\nthrough the National Research Foundation of Korea (NRF)\nfunded by the Ministry of Science, ICT, & Future Planning\n(Grant no. NRF-2017M3C7A1044815). This was also supported\nby the “Research Base Construction Fund Support\nProgram” funded by Chonbuk National University in 2018.\nReferences\n[1] Z. Dai, R. Ziebold, A. Born, and E. Engler, “Heading-determination\nusing the sensor-fusion based maritime PNT unit,” in\nProceedings of the 2012 IEEE/ION Position, Location and Navigation\nSymposium, pp. 799–807, South Carolina, USA, 2012.\n[2] S. He, J. Zhang, Y. Cheng, X. Wan, and B. Ran, “Freeway multisensor\ndata fusion approach integrating data from cellphone\nprobes and fixed sensors,” Journal of Sensors, vol. 2016, Article\nID 7269382, 13 pages, 2016.\n[3] H. Men, D. Chen, X. Zhang, J. Liu, and K. Ning, “Data fusion\nof electronic nose and electronic tongue for detection of mixed\nedible-oil,” Journal of Sensors, vol. 2014, Article ID 840685, 7\npages, 2014.\n[4] J. Li, J. A. Besada, A. M. Bernardos, P. Tarrío, and J. R. Casar,\n“A novel system for object pose estimation using fused vision\nand inertial data,” Information Fusion, vol. 33, pp. 15–28,\n2017.\n[5] J. Wu, Y. Feng, and P. Sun, “Sensor fusion for recognition of\nactivities of daily living,” Sensors, vol. 18, no. 11, 2018.\n[6] S.W.Yoon,S.-B.Park, andJ.S.Kim,“Kalmanfilter sensor fusion\nfor Mecanum wheeled automated guided vehicle localization,”\nJournal of Sensors, vol. 2015, Article ID 347379, 7 pages, 2015.\n[7] Q. Li, D. C. Li, Q. F. Wu et al., “Autonomous navigation and\nenvironment modeling for MAVs in 3-D enclosed industrial\nenvironments,” Computers in Industry, vol. 64, no. 9,\npp. 1161–1177, 2013.\n[8] M. C. P. Santos, L. V. Santana, A. S. Brandão,\nM. Sarcinelli-Filho, and R. Carelli, “Indoor low-cost localization\nsystem for controlling aerial robots,” Control Engineering\nPractice, vol. 61, pp. 93–111, 2017.\n[9] M.Barisic,N.Miskovic, andA.Vasilijevic, “Fusinghydroacoustic\nabsolute positionfixeswithAUVon-board dead reckoning,”\nIFAC Proceedings Volumes, vol. 45, no. 22, pp. 211–217, 2012.\n[10] C. Melendez-Pastor, R. Ruiz-Gonzalez, and J. Gomez-Gil, “A\ndata fusion system of GNSS data and on-vehicle sensors data\nfor improving car positioning precision in urban environments,”\nExpert Systems with Applications, vol. 80, pp. 28–38, 2017.\n[11] J. H. Lim, W. Yoo, L. Kim, Y. Lee, and H. Lee, “Augmentation\nof GNSS by low-cost MEMS IMU, OBD-II, and digital altimeter\nfor improved positioning in urban area,” Sensors, vol. 18,\nno. 11, 2018.\n[12] S. Qiu, Z. Wang, H. Zhao, K. Qin, Z. Li, and H. Hu, “Inertial/\nmagnetic sensors based pedestrian dead reckoning by\nmeans of multi-sensor fusion,” Information Fusion, vol. 39,\npp. 108–119, 2018.\n[13] Widyawan, G. Pirkl, D. Munaretto et al., “Virtual lifeline: multimodal\nsensor data fusion for robust navigation in unknown\nenvironments,” Pervasive and Mobile Computing, vol. 8,\nno. 3, pp. 388–401, 2012.\n[14] M. D. N. Forte, W. B. Correia, F. G. Nogueira, and B. C. Torrico,\n“Reference tracking of a nonholonomic mobile robot\nusing sensor fusion techniques and linear control,” IFAC-PapersOnLine,\nvol. 51, no. 4, pp. 364–369, 2018.\n[15] H. Lee and S. Jung, “Balancing and navigation control of a\nmobile inverted pendulum robot using sensor fusion of low\ncost sensors,” Mechatronics, vol. 22, no. 1, pp. 95–105, 2012.\n[16] J. Kowalski, P. Linder, S. Zierke et al., “Navigation technology\nfor exploration of glacier ice with maneuverable melting\nprobes,” Cold Regions Science and Technology, vol. 123,\npp. 53–70, 2016.\n[17] J. Delaune, G. Le Besnerais, T. Voirin, J. L. Farges, and\nC. Bourdarias, “Visual–inertial navigation for pinpoint planetary\nlanding using scale-based landmark matching,” Robotics\nand Autonomous Systems, vol. 78, pp. 63–82, 2016.\n[18] B. Brzozowski, Z. Rochala, K. Wojtowicz, and P. Wieczorek,\n“Measurement data fusion with cascaded Kalman and complementary\nfilter in the flight parameter indicator for hang-glider\nand paraglider,” Measurement, vol. 123, pp. 94–101, 2018.\n[19] F. Abyarjoo, A. Barreto, J. Cofino, and F. R. Ortega, “Implementing\na sensor fusion algorithm for 3D orientation detec-\ntion with inertial/magnetic sensors,” in Innovations and\nAdvances in Computing, Informatics, Systems Sciences, Networking\nand Engineering, Lecture Notes in Electrical Engineer-\ning, pp. 305–310, Springer, 2015.\n[20] T. Kim and B. Song, “Detection and tracking of road barrier\nbased on radar and vision sensor fusion,” Journal of Sensors,\nvol. 2016, Article ID 1963450, 8 pages, 2016.\n[21] J. Feng, W. Zhou, and K. Sun, “Multimedia fusion for public\nsecurity in heterogeneous sensor networks,” Journal of Sensors,\nvol. 2014, Article ID 273210, 12 pages, 2014.\n12 Journal of Sensors\n', "[22] A. Trzuskowsky, C. Hoelper, and D. Abel, “ANCHOR: navigation,\nrouting and collision warning during operations in har-\nbors,” IFAC-PapersOnLine, vol. 49, no. 23, pp. 220–225, 2016.\n[23] W. C. Bruhn, H.-C. Burmeister, M. T. Long, and J. A. Moræus,\n“Conducting look-out on an unmanned vessel: Introduction to\nthe advanced sensor module for MUNIN’s autonomous dry\nbulk carrier,” in Proceedings of International Symposium Information\non Ships—ISIS 2014, pp. 141–154, Hamburg, Ger-\nmany, 2014.\n[24] A. L. Flåten and E. F. Brekke, “Performance prediction of\ntracking sensors for surface vehicle collision avoidance,” in\n2016 19th International Conference on Information Fusion\n(FUSION), pp. 1894–1900, Heidelberg, Germany, 2016.\n[25] D. Chen, C. Dai, X. Wan, and J. Mou, “A research on\nAIS-based embedded system for ship collision avoidance,” in\n2015 International Conference on Transportation Information\nand Safety (ICTIS), pp. 512–517, Wuhan, China, 2015.\n[26] P. Hu and C. Huang, “Shipborne high-accuracy heading determinationmethod\nusing INS- andGPS-based heading determination\nsystem,” GPS Solutions, vol. 21, no. 3, pp. 1059–1068, 2017.\n[27] J. C. Juang and C. F. Lin, “A sensor fusion scheme for the estimation\nof vehicular speed and heading angle,” IEEE Transac-\ntions on Vehicular Technology, vol. 64, no. 7, pp. 2773–2782,\n2015.\n[28] Q. Feng-de, W. Feng-wu, L. Jiang, and T. Guan-jun, “A\nmethod for the measurement of ship attitude based on\nmulti-sensor data fusion,” in 2015 Ninth International\nConference on Frontier of Computer Science and Technology,\npp. 196–199, Dalian, China, 2015.\n[29] T. H. Bryne, Nonlinear Observer Design for Aided Inertial\nNavigation of Ships, [Ph.D. thesis], NTNU, Trondheim, Norway,\n2017.\n[30] K. Jaroś, A. Witkowska, and R. Śmierzchalski, “Data fusion of\nGPS sensors using particle Kalman filter for ship dynamic\npositioning system,” in 2017 22nd International Conference\non Methods and Models in Automation and Robotics (MMAR),\npp. 89–94, Miedzyzdroje, Poland, 2017.\n[31] J. M. Núñez, M. G. Araújo, and I. García-Tuñón, “Real-time\ntelemetry system for monitoring motion of ships based on\ninertial sensors,” Sensors, vol. 17, no. 5, p. 948, 2017.\n[32] E. Borràs, J. Ferré, R. Boqué, M. Mestres, L. Aceña, and\nO. Busto, “Data fusion methodologies for food and beverage\nauthentication and quality assessment – a review,” Analytica\nChimica Acta, vol. 891, pp. 1–14, 2015.\n[33] C. Chen, R. Jafari, and N. Kehtarnavaz, “A real-time human\naction recognition system using depth and inertial sensor\nfusion,” IEEE Sensors Journal, vol. 16, no. 3, pp. 773–781, 2016.\n[34] Z. Ercan, V. Sezer, H. Heceoglu et al., “Multi-sensor data\nfusion of DCM based orientation estimation for land vehicles,”\nin 2011 IEEE International Conference onMechatronics (ICM),\npp. 672–677, Istanbul, Turkey, 2011.\n[35] Y. L. Zhang, J. H. Park, N. O. Sel, and K. T. Chong, “Robot navigation\nusing a DR/GPS data fusion,” Applied Mechanics and\nMaterials, vol. 392, pp. 261–266, 2013.\n[36] M. A. A. Akhoundi and E. Valavi, “Multi-sensor fuzzy data\nfusion using sensors with different characteristics,” 2010,\nhttp://arxiv.org/abs/1010.6096.\n[37] T. Yairi, K. Hori, and S. Nakasuka, “Sensor space discretization\nin autonomous agent based on entropyminimization of behavior\noutcomes,” in Proceedings. 1999 IEEE/SICE/RSJ. Interna-\ntional Conference on Multisensor Fusion and Integration for\nIntelligent Systems. MFI'99 (Cat. No.99TH8480), pp. 111–116,\nTaipei, Taiwan, 1999.\n[38] P. Scherz, A. Haderer, K. Pourvoyeur, and A. Stelzer, “Embedded\nsensor fusion system for unmanned vehicle navigation,” in\n2008 IEEE/ASME International Conference on Mechtronic and\nEmbedded Systems and Applications, pp. 192–197, Beijing,\nChina, 2008.\n[39] F. P. Vista IV, D.-J. Lee, and K. T. Chong, “Design of an\nEKF-CI based sensor fusion for robust heading estimation of\nmarine vehicle,” International Journal of Precision Engineering\nand Manufacturing, vol. 16, no. 2, pp. 403–407, 2015.\n[40] F. P. Vista IV and K. T. Chong, “Design, development, and\ndeployment of real-time sensor fusion (CnW+EKF) for a\nLinux-based embedded system using Qt-anywhere,” Journal\nof Sensors, vol. 2018, Article ID 8695397, 14 pages, 2018.\n[41] US Army, AdvancedMap and Aerial Photograph Reading, U.S.\nArmy Headquarters, War Department, 1941.\n[42] D. DePriest, NMEA Data, GPS NMEA Information, 2019,\nhttps://www.gpsinformation.org/dale/nmea.htm.\n[43] C. Dussault, R. Courtois, J.-P. Ouellet, and J. Huot, “Influence\nof satellite geometry and differential correction on GPS location\naccuracy,” Wildlife Society Bulletin, vol. 29, no. 1,\npp. 171–179, 2001.\n[44] M. F. Yuen, Dilution of Precision (DOP) Calculation for Mission\nPlanning Purposes, Naval Postgraduate School, Monterey,\nCA, Californina, 2009.\n[45] S. Elizabeth and R. Jothilakshmi, “Convergence analysis of\nextended Kalman filter in a noisy environment through\ndifference equations,” International Journal of Differential\nEquations and Applications, vol. 14, no. 2, 2015.\n[46] E. Kamrani, A. N. Foroushani, M. Vaziripour, and M. Sawan,\n“Detecting the stable, observable and controllable states of\nthe human brain dynamics,” Open Journal of Medical Imaging,\nvol. 2, no. 4, pp. 128–136, 2012.\n[47] B. Southall, B. F. Buxton, and J. A. Marchant, “Controllability\nand observability: tools for kalman filter design,” in Proceedings\nof the British Machine Vision Conference 1998, pp. 17.1–\n17.10, Southampton, UK, 1998.\n[48] S. Julier and J. K. Uhlmann, “General decentralized data fusion\nwith covariance intersection,” in Handbook of Multisensor\nData Fusion: Theory and Practice, pp. 319–344, CRC Press,\nBoca Raton, FL, USA, 2009.\n[49] S. D. Levy, “TinyEKF, GitHub,” 2019, https://github.com/\nsimondlevy/TinyEKF.\n13Journal of Sensors\n"]</pre>
    </body>
    </html>
    